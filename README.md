# Image-to-sketch-using-autoencoder

An autoencoder is a unique form of deep learning architecture that comprises two main components: an encoder and a decoder. The encoder may take the form of either a fully connected dense neural network or a convolutional neural network (CNN). Its purpose is to reduce the dimensionality of the input image by passing it through convolutional layers and max-pooling operations, resulting in a latent vector representation. Similarly, the decoder, which can also be a fully connected or convolutional neural network, is responsible for reconstructing the original input from the downsampled latent vector produced by the encoder. This reconstructed output is then compared to the original input, and a reconstruction loss is computed. By leveraging backpropagation, the autoencoder aims to minimize this loss, thereby fine-tuning its ability to accurately reconstruct input images. Simple autoencoders find application in diverse tasks such as domain transformation, image denoising, colorization, and anomaly detection. In this context, the objective is to train an autoencoder model specifically to generate sketches based on input images.
